[{"authors":["admin"],"categories":null,"content":"I am a Ph.D. candidate in the Department of Electrical and Computer Engineering at Purdue University, advised by Prof. Kaushik Roy. My research interests lie at the intersection of deep learning and edge computing. I focus on developing energy-efficient and robust deep learning algorithms, with special interests in spiking neural networks and computer vision for event-based cameras.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://chan8972.github.io/author/chankyu-lee/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chankyu-lee/","section":"authors","summary":"I am a Ph.D. candidate in the Department of Electrical and Computer Engineering at Purdue University, advised by Prof. Kaushik Roy. My research interests lie at the intersection of deep learning and edge computing.","tags":null,"title":"Chankyu Lee","type":"authors"},{"authors":["Chankyu Lee","Adarsh Kosta","Alex Zihao Zhu","Kenneth Chaney","Kostas Daniilidis","Kaushik Roy"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"8491962f1646f70b69180307330719f3","permalink":"https://chan8972.github.io/publication/2020-eccv/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/2020-eccv/","section":"publication","summary":"Event-based cameras display great potential for a variety of conditions such as high-speed motion detection and enabling navigation in low-light environments where conventional frame-based cameras suffer critically. This is attributed to their high temporal resolution, high dynamic range, and low-power consumption. However, conventional computer vision methods as well as deep Analog Neural Networks (ANNs) are not suited to work well with the asynchronous and discrete nature of event camera outputs. Spiking Neural Networks (SNNs) serve as ideal paradigms to handle event camera outputs, but deep SNNs suffer in terms of performance due to spike vanishing phenomenon. To overcome these issues, we present Spike-FlowNet, a deep hybrid neural network architecture integrating SNNs and ANNs for efficiently estimating optical flow from sparse event camera outputs without sacrificing the performance. The network is end-to-end trained with self-supervised learning on Multi-Vehicle Stereo Event Camera (MVSEC) dataset. Spike-FlowNet outperforms its corresponding ANN-based method in terms of the optical flow prediction capability while providing significant computational efficiency.","tags":null,"title":"Spike-FlowNet: Event-based Optical Flow Estimation with Energy-Efficient Hybrid Neural Networks","type":"publication"},{"authors":["Sayeed Shafayet Chowdhury*","Chankyu Lee*","Kaushik Roy (*Equal Contribution)"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"3d2f6a8460c5d957caf50e6bd283275e","permalink":"https://chan8972.github.io/publication/2020-arxiv/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/2020-arxiv/","section":"publication","summary":"Spiking Neural Networks (SNNs) are being explored to emulate the astounding capabilities of human brain that can learn and compute functions robustly and efficiently with noisy spiking activities. A variety of spiking neuron models have been proposed to resemble biological neuronal functionalities. With varying levels of bio-fidelity, these models often contain a leak path in their internal states, called membrane potentials. While the leaky models have been argued as more bioplausible, a comparative analysis between models with and without leak from a purely computational point of view demands attention. In this paper, we investigate the questions regarding the justification of leak and the pros and cons of using leaky behavior. Our experimental results reveal that leaky neuron model provides improved robustness and better generalization compared to models with no leak. However, leak decreases the sparsity of computation contrary to the common notion. Through a frequency domain analysis, we demonstrate the effect of leak in eliminating the high-frequency components from the input, thus enabling SNNs to be more robust against noisy spike-inputs.","tags":null,"title":"Towards Understanding the Effect of Leak in Spiking Neural Networks","type":"publication"},{"authors":["Frank Pennekamp","Jean Clobert","Nicolas Schtickzelle"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"79ade04fcea75bff28e91bbe1f50fdb2","permalink":"https://chan8972.github.io/publication/2020-frontier/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/2020-frontier/","section":"publication","summary":"Understanding how and why individual movement translates into dispersal between populations is a long-term goal in ecology. Movement is broadly defined as ‘any change in the spatial location of an individual’, whereas dispersal is more narrowly defined as a movement that may lead to gene flow. Because the former may create the condition for the latter, behavioural decisions that lead to dispersal may be detectable in underlying movement behaviour. In addition, dispersing individuals also have specific sets of morphological and behavioural traits that help them coping with the costs of movement and dispersal, and traits that mitigate costs should be under selection and evolve if they have a genetic basis. Here, we experimentally study the relationships between movement behaviour, morphology and dispersal across 44 genotypes of the actively dispersing unicellular, aquatic model organism Tetrahymena thermophila. We used two-patch populations to quantify individual movement trajectories, as well as activity, morphology and dispersal rate. First, we studied variation in movement behaviour among and within genotypes (i.e. between dispersers and residents) and tested whether this variation can be explained by morphology. Then, we addressed how much the dispersal rate is driven by differences in the underlying movement behaviour. Genotypes revealed clear differences in terms of movement speed and linearity. We also detected marked movement differences between resident and dispersing individuals, mediated by the genotype. Movement variation was partly explained by morphological properties such as cell size and shape, with larger cells consistently showing higher movement speed and higher linearity. Genetic differences in activity and movement were positively related to the observed dispersal and jointly explained 47\\% of the variation in dispersal rate. Our study shows that a detailed understanding of the interplay between morphology, movement and dispersal may have potential to improve dispersal predictions over broader spatio-temporal scales.","tags":[],"title":"The interplay between movement, morphology and dispersal in Tetrahymena ciliates","type":"publication"},{"authors":["Chankyu Lee","Gopalakrishnan Srinivasan","Priyadarshini Panda","Kaushik Roy"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"3fef110b6b780edb3c365a011a330684","permalink":"https://chan8972.github.io/publication/2018-tcds/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/2018-tcds/","section":"publication","summary":"Spiking neural networks (SNNs) have emerged as a promising brain inspired neuromorphic-computing paradigm for cognitive system design due to their inherent event-driven processing capability. The fully connected (FC) shallow SNNs typically used for pattern recognition require large number of trainable parameters to achieve competitive classification accuracy. In this paper, we propose a deep spiking convolutional neural network (SpiCNN) composed of a hierarchy of stacked convolutional layers followed by a spatial-pooling layer and a final FC layer. The network is populated with biologically plausible leaky-integrate-and-fire (LIF) neurons interconnected by shared synaptic weight kernels. We train convolutional kernels layer-by-layer in an unsupervised manner using spike-timingdependent plasticity (STDP) that enables them to self-learn characteristic features making up the input patterns. In order to further improve the feature learning efficiency, we propose using smaller 3×3 kernels trained using STDP-based synaptic weight updates performed over a mini-batch of input patterns. Our deep SpiCNN, consisting of two convolutional layers trained using the unsupervised convolutional STDP learning methodology, achieved classification accuracies of 91.1% and 97.6%, respectively, for inferring handwritten digits from the MNIST data set and a subset of natural images from the Caltech data set.","tags":null,"title":"Deep Spiking Convolutional Neural Network Trained With Unsupervised Spike-Timing-Dependent Plasticity","type":"publication"},{"authors":["Chankyu Lee","Gopalakrishnan Srinivasan","Priyadarshini Panda","Kaushik Roy"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"9e9a7821e073aa9205b2c86bbec34c07","permalink":"https://chan8972.github.io/publication/2018-frontier/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/2018-frontier/","section":"publication","summary":"Spiking neural networks (SNNs) have emerged as a promising brain inspired neuromorphic-computing paradigm for cognitive system design due to their inherent event-driven processing capability. The fully connected (FC) shallow SNNs typically used for pattern recognition require large number of trainable parameters to achieve competitive classification accuracy. In this paper, we propose a deep spiking convolutional neural network (SpiCNN) composed of a hierarchy of stacked convolutional layers followed by a spatial-pooling layer and a final FC layer. The network is populated with biologically plausible leaky-integrate-and-fire (LIF) neurons interconnected by shared synaptic weight kernels. We train convolutional kernels layer-by-layer in an unsupervised manner using spike-timingdependent plasticity (STDP) that enables them to self-learn characteristic features making up the input patterns. In order to further improve the feature learning efficiency, we propose using smaller 3×3 kernels trained using STDP-based synaptic weight updates performed over a mini-batch of input patterns. Our deep SpiCNN, consisting of two convolutional layers trained using the unsupervised convolutional STDP learning methodology, achieved classification accuracies of 91.1% and 97.6%, respectively, for inferring handwritten digits from the MNIST data set and a subset of natural images from the Caltech data set.","tags":null,"title":"Training deep spiking convolutional neural networks with stdp-based unsupervised pre-training followed by supervised fine-tuning","type":"publication"}]